#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
AI-CloudOps-aiops
Author: Bamboo
Email: bamboocloudops@gmail.com
License: Apache 2.0
Description: AI-CloudOpsæ™ºèƒ½æŠ¥å‘Šç”Ÿæˆå™¨ - åŸºäºå¤§æ¨¡å‹ç”Ÿæˆç»¼åˆé¢„æµ‹åˆ†ææŠ¥å‘Š
"""

import json
import logging
from dataclasses import dataclass
from datetime import datetime
from typing import Any, Dict, List, Optional

from app.core.interfaces.llm_client import LLMClient, NullLLMClient
from app.core.prediction.prompt_templates import prompt_builder
from app.models import PredictionType

logger = logging.getLogger("aiops.core.prediction.report_generator")


@dataclass
class ReportContext:
    """æŠ¥å‘Šç”Ÿæˆä¸Šä¸‹æ–‡"""

    prediction_type: PredictionType
    analysis_context: Dict[str, Any]
    prediction_results: Dict[str, Any]
    interpretation: Dict[str, Any]
    insights: List[str]
    scaling_recommendations: List[Dict[str, Any]]
    cost_analysis: Optional[Dict[str, Any]]
    quantitative_metrics: Dict[str, Any]


class IntelligentReportGenerator:
    """æŠ¥å‘Šç”Ÿæˆå™¨ - ç»“åˆå¤–éƒ¨åˆ†æç”Ÿæˆå¤šæ ·åŒ–æŠ¥å‘Š"""

    def __init__(self, llm_client: Optional[LLMClient] = None):
        # é»˜è®¤ä½¿ç”¨ç©ºå®ç°ï¼ŒæœåŠ¡å±‚å¯æ³¨å…¥çœŸå®å®ç°
        self.llm_service: LLMClient = llm_client or NullLLMClient()

    def _safe_get_dict(
        self, data: Any, default: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """å®‰å…¨è·å–å­—å…¸æ•°æ®"""
        if isinstance(data, dict):
            return data
        return default if default is not None else {}

    def _safe_get_value(self, data: Any, key: str, default: Any = None) -> Any:
        """å®‰å…¨è·å–å­—å…¸å€¼"""
        if isinstance(data, dict):
            return data.get(key, default)
        return default

    async def generate_comprehensive_report(
        self,
        report_context: ReportContext,
        report_style: str = "professional",
        include_charts_desc: bool = True,
    ) -> Dict[str, Any]:
        """ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š"""
        try:
            # å‡†å¤‡æŠ¥å‘Šæ•°æ®
            report_data = self._prepare_report_data(report_context)

            # æ ¹æ®é£æ ¼é€‰æ‹©æ¨¡æ¿å’Œå‚æ•°
            template_params = self._get_template_params(report_style)

            # æ„å»ºæŠ¥å‘Šç”Ÿæˆæç¤º
            prompt = await self._build_comprehensive_prompt(
                report_data, template_params, include_charts_desc
            )

            # ç”ŸæˆæŠ¥å‘Š
            report_content = await self.llm_service.generate_response(
                messages=[{"role": "user", "content": prompt}],
                temperature=template_params.get("temperature", 0.3),
                max_tokens=template_params.get("max_tokens", 1500),
                use_task_model=False,  # å¤æ‚æ“ä½œï¼šç”Ÿæˆç»¼åˆæŠ¥å‘Šï¼Œä½¿ç”¨ä¸»æ¨¡å‹
            )

            if report_content:
                # ç”Ÿæˆæ‰§è¡Œæ‘˜è¦
                executive_summary = await self._generate_executive_summary(
                    report_context, report_content
                )

                # ç”Ÿæˆå…³é”®æŒ‡æ ‡æ‘˜è¦
                key_metrics = self._extract_key_metrics(report_context)

                return {
                    "status": "success",
                    "report": {
                        "executive_summary": executive_summary,
                        "full_content": report_content,
                        "key_metrics": key_metrics,
                        "report_metadata": {
                            "generated_at": datetime.now(),
                            "prediction_type": report_context.prediction_type.value,
                            "report_style": report_style,
                            "data_quality_score": self._assess_data_quality(
                                report_context
                            ),
                        },
                    },
                }
            else:
                return self._generate_fallback_report(report_context)

        except Exception as e:
            logger.error(f"ç”Ÿæˆç»¼åˆæŠ¥å‘Šå¤±è´¥: {str(e)}")
            return self._generate_fallback_report(report_context)

    async def generate_executive_summary(
        self, report_context: ReportContext, max_length: int = 300
    ) -> Dict[str, Any]:
        """ç”Ÿæˆæ‰§è¡Œæ‘˜è¦ - ç®€çŸ­çš„é«˜å±‚å†³ç­–æ¦‚è¦"""
        try:
            summary_prompt = f"""åŸºäºä»¥ä¸‹{report_context.prediction_type.value}é¢„æµ‹åˆ†æï¼Œç”Ÿæˆä¸€ä»½ç®€æ´çš„æ‰§è¡Œæ‘˜è¦ï¼ˆ{max_length}å­—ä»¥å†…ï¼‰ï¼š

å…³é”®æŒ‡æ ‡ï¼š
- é¢„æµ‹è¶‹åŠ¿: {self._get_trend_summary(report_context)}
- é£é™©ç­‰çº§: {self._assess_risk_level(report_context)}
- èµ„æºå»ºè®®: {len(report_context.scaling_recommendations)}é¡¹å»ºè®®
- æˆæœ¬å½±å“: {self._get_cost_impact_summary(report_context)}

æ´å¯Ÿè¦ç‚¹ï¼š
{chr(10).join(report_context.insights[:3])}

è¯·ç”ŸæˆåŒ…å«ä»¥ä¸‹è¦ç´ çš„æ‰§è¡Œæ‘˜è¦ï¼š
1. ä¸€å¥è¯æ¦‚è¿°å½“å‰çŠ¶å†µ
2. æœ€å…³é”®çš„1-2ä¸ªå‘ç°
3. æœ€é‡è¦çš„å»ºè®®è¡ŒåŠ¨
4. é¢„æœŸæ—¶é—´æ¡†æ¶

è¦æ±‚ï¼šè¯­è¨€ç®€æ´ã€å†³ç­–å¯¼å‘ã€çªå‡ºè¡ŒåŠ¨è¦ç‚¹ã€‚"""

            summary_response = await self.llm_service.generate_response(
                messages=[{"role": "user", "content": summary_prompt}],
                temperature=0.2,
                max_tokens=400,
                use_task_model=False,  # å¤æ‚æ“ä½œï¼šç”Ÿæˆæ‰§è¡Œæ‘˜è¦ï¼Œä½¿ç”¨ä¸»æ¨¡å‹
            )

            if summary_response:
                return {
                    "status": "success",
                    "summary": summary_response,
                    "word_count": len(summary_response),
                    "generated_at": datetime.now(),
                }
            else:
                return self._generate_fallback_summary(report_context)

        except Exception as e:
            logger.error(f"ç”Ÿæˆæ‰§è¡Œæ‘˜è¦å¤±è´¥: {str(e)}")
            return self._generate_fallback_summary(report_context)

    async def generate_action_plan(
        self, report_context: ReportContext, time_horizon: str = "weekly"
    ) -> Dict[str, Any]:
        """ç”Ÿæˆè¡ŒåŠ¨è®¡åˆ’"""
        try:
            time_configs = {
                "daily": {"steps": 3, "detail_level": "å…·ä½“æ“ä½œ"},
                "weekly": {"steps": 5, "detail_level": "é˜¶æ®µæ€§ä»»åŠ¡"},
                "monthly": {"steps": 4, "detail_level": "æˆ˜ç•¥æ€§ç›®æ ‡"},
            }

            config = time_configs.get(time_horizon, time_configs["weekly"])

            action_prompt = f"""åŸºäº{report_context.prediction_type.value}é¢„æµ‹åˆ†æï¼Œåˆ¶å®š{time_horizon}è¡ŒåŠ¨è®¡åˆ’ï¼š

é¢„æµ‹æ¦‚å†µï¼š
{self._format_prediction_overview(report_context)}

æ‰©ç¼©å®¹å»ºè®®ï¼š
{self._format_scaling_recommendations(report_context)}

è¯·ç”Ÿæˆ{config["steps"]}æ­¥çš„è¡ŒåŠ¨è®¡åˆ’ï¼Œæ¯æ­¥åŒ…å«ï¼š
- è¡ŒåŠ¨é¡¹ç›®ï¼ˆ{config["detail_level"]}ï¼‰
- æ‰§è¡Œæ—¶é—´
- è´Ÿè´£å›¢é˜Ÿå»ºè®®
- é¢„æœŸç»“æœ
- é£é™©æ§åˆ¶

è¦æ±‚ï¼šå¯æ‰§è¡Œã€æœ‰æ—¶é—´èŠ‚ç‚¹ã€è€ƒè™‘ä¾èµ–å…³ç³»ã€‚"""

            plan_response = await self.llm_service.generate_response(
                messages=[{"role": "user", "content": action_prompt}],
                temperature=0.3,
                max_tokens=800,
                use_task_model=False,  # å¤æ‚æ“ä½œï¼šç”Ÿæˆè¡ŒåŠ¨è®¡åˆ’ï¼Œä½¿ç”¨ä¸»æ¨¡å‹
            )

            if plan_response:
                parsed_plan = self._parse_action_plan(plan_response)

                return {
                    "status": "success",
                    "action_plan": {
                        "time_horizon": time_horizon,
                        "plan_content": plan_response,
                        "parsed_actions": parsed_plan,
                        "priority_actions": self._identify_priority_actions(
                            parsed_plan
                        ),
                        "generated_at": datetime.now(),
                    },
                }
            else:
                return self._generate_fallback_action_plan(report_context, time_horizon)

        except Exception as e:
            logger.error(f"ç”Ÿæˆè¡ŒåŠ¨è®¡åˆ’å¤±è´¥: {str(e)}")
            return self._generate_fallback_action_plan(report_context, time_horizon)

    async def generate_risk_assessment_report(
        self, report_context: ReportContext
    ) -> Dict[str, Any]:
        """ç”Ÿæˆé£é™©è¯„ä¼°æŠ¥å‘Š"""
        try:
            risk_data = self._analyze_risks(report_context)

            risk_prompt = f"""åŸºäº{report_context.prediction_type.value}é¢„æµ‹ï¼Œè¿›è¡Œé£é™©è¯„ä¼°åˆ†æï¼š

æ£€æµ‹åˆ°çš„é£é™©ç‚¹ï¼š
{json.dumps(risk_data, ensure_ascii=False, indent=2)}

è¯·ä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œé£é™©è¯„ä¼°ï¼š

## ğŸš¨ é£é™©è¯†åˆ«
è¯†åˆ«ä¸»è¦é£é™©ç±»å‹å’Œè§¦å‘æ¡ä»¶

## ğŸ“Š å½±å“åˆ†æ  
è¯„ä¼°é£é™©å¯¹ä¸šåŠ¡å’Œç³»ç»Ÿçš„æ½œåœ¨å½±å“

## âš¡ ç´§æ€¥ç¨‹åº¦
æ ¹æ®æ—¶é—´ç´§è¿«æ€§å¯¹é£é™©è¿›è¡Œä¼˜å…ˆçº§æ’åº

## ğŸ›¡ï¸ ç¼“è§£ç­–ç•¥
é’ˆå¯¹æ¯ç±»é£é™©æå‡ºå…·ä½“çš„åº”å¯¹æªæ–½

## ğŸ“ˆ ç›‘æ§å»ºè®®
å»ºè®®éœ€è¦åŠ å¼ºç›‘æ§çš„å…³é”®æŒ‡æ ‡

è¦æ±‚ï¼šå®¢è§‚åˆ†æã€é‡åŒ–å½±å“ã€å¯æ“ä½œå»ºè®®ã€‚"""

            risk_response = await self.llm_service.generate_response(
                messages=[{"role": "user", "content": risk_prompt}],
                temperature=0.2,
                max_tokens=1000,
                use_task_model=False,  # å¤æ‚æ“ä½œï¼šé£é™©è¯„ä¼°ï¼Œä½¿ç”¨ä¸»æ¨¡å‹
            )

            if risk_response:
                return {
                    "status": "success",
                    "risk_assessment": {
                        "assessment_content": risk_response,
                        "risk_score": self._calculate_risk_score(report_context),
                        "critical_risks": risk_data.get("critical_risks", []),
                        "risk_timeline": self._generate_risk_timeline(report_context),
                        "generated_at": datetime.now(),
                    },
                }
            else:
                return self._generate_fallback_risk_assessment(report_context)

        except Exception as e:
            logger.error(f"ç”Ÿæˆé£é™©è¯„ä¼°æŠ¥å‘Šå¤±è´¥: {str(e)}")
            return self._generate_fallback_risk_assessment(report_context)

    async def generate_cost_optimization_report(
        self, report_context: ReportContext
    ) -> Optional[Dict[str, Any]]:
        """ç”Ÿæˆæˆæœ¬ä¼˜åŒ–æŠ¥å‘Š"""
        if not report_context.cost_analysis:
            return None

        try:
            cost_data = self._safe_get_dict(report_context.cost_analysis)

            cost_prompt = f"""åŸºäº{report_context.prediction_type.value}é¢„æµ‹å’Œæˆæœ¬åˆ†æï¼Œç”Ÿæˆæˆæœ¬ä¼˜åŒ–æŠ¥å‘Šï¼š

æˆæœ¬åˆ†ææ•°æ®ï¼š
{json.dumps(cost_data, ensure_ascii=False, indent=2)}

æ‰©ç¼©å®¹å»ºè®®ï¼š
{self._format_scaling_recommendations(report_context)}

è¯·ç”Ÿæˆæˆæœ¬ä¼˜åŒ–åˆ†æï¼š

## ğŸ’° æˆæœ¬ç°çŠ¶
å½“å‰æˆæœ¬ç»“æ„å’Œä¸»è¦å¼€é”€é¡¹ç›®

## ğŸ“ˆ æˆæœ¬é¢„æµ‹
åŸºäºé¢„æµ‹ç»“æœçš„æˆæœ¬å˜åŒ–è¶‹åŠ¿

## ğŸ’¡ ä¼˜åŒ–æœºä¼š
è¯†åˆ«çš„æˆæœ¬èŠ‚çœæœºä¼šå’Œä¼˜åŒ–ç‚¹

## ğŸ¯ ä¼˜åŒ–å»ºè®®
å…·ä½“çš„æˆæœ¬ä¼˜åŒ–æªæ–½å’Œé¢„æœŸæ•ˆæœ

## âš–ï¸ é£é™©æƒè¡¡
æˆæœ¬ä¼˜åŒ–å¯èƒ½å¸¦æ¥çš„æ€§èƒ½æˆ–å¯é æ€§é£é™©

è¦æ±‚ï¼šé‡åŒ–åˆ†æã€ROIè¯„ä¼°ã€å¹³è¡¡å»ºè®®ã€‚"""

            cost_response = await self.llm_service.generate_response(
                messages=[{"role": "user", "content": cost_prompt}],
                temperature=0.3,
                max_tokens=900,
                use_task_model=False,  # å¤æ‚æ“ä½œï¼šæˆæœ¬ä¼˜åŒ–æŠ¥å‘Šï¼Œä½¿ç”¨ä¸»æ¨¡å‹
            )

            if cost_response:
                return {
                    "status": "success",
                    "cost_optimization": {
                        "report_content": cost_response,
                        "potential_savings": cost_data.get("cost_savings_potential", 0),
                        "optimization_priority": self._assess_cost_optimization_priority(
                            cost_data
                        ),
                        "generated_at": datetime.now(),
                    },
                }
            else:
                return {"status": "fallback", "message": "æˆæœ¬ä¼˜åŒ–æŠ¥å‘Šç”Ÿæˆå¤±è´¥"}

        except Exception as e:
            logger.error(f"ç”Ÿæˆæˆæœ¬ä¼˜åŒ–æŠ¥å‘Šå¤±è´¥: {str(e)}")
            return {"status": "error", "message": str(e)}

    def _prepare_report_data(self, context: ReportContext) -> Dict[str, Any]:
        """å‡†å¤‡æŠ¥å‘Šæ•°æ®"""
        try:
            # å®‰å…¨è·å–å„ç§æ•°æ®ï¼Œç¡®ä¿éƒ½æ˜¯å­—å…¸ç±»å‹
            analysis_context = self._safe_get_dict(context.analysis_context)
            prediction_results = self._safe_get_dict(context.prediction_results)
            interpretation = self._safe_get_dict(context.interpretation)
            quantitative_metrics = self._safe_get_dict(context.quantitative_metrics)

            # æå–åˆ†ææ‘˜è¦
            if isinstance(context.analysis_context, str):
                analysis_summary = context.analysis_context
            else:
                analysis_dict = self._safe_get_dict(
                    self._safe_get_value(analysis_context, "analysis", {})
                )
                analysis_summary = self._safe_get_value(analysis_dict, "summary", "")

            # æå–è§£é‡Šæ‘˜è¦
            if isinstance(context.interpretation, str):
                interpretation_summary = context.interpretation
            else:
                interpretation_summary = self._safe_get_value(
                    interpretation, "interpretation_summary", ""
                )

            return {
                "prediction_type": context.prediction_type.value,
                "analysis_summary": analysis_summary,
                "interpretation_summary": interpretation_summary,
                "key_insights": context.insights,
                "quantitative_metrics": quantitative_metrics,
                "scaling_count": len(
                    context.scaling_recommendations
                    if context.scaling_recommendations
                    else []
                ),
                "anomaly_count": len(
                    self._safe_get_value(prediction_results, "anomaly_predictions", [])
                ),
                "prediction_summary": self._safe_get_value(
                    prediction_results, "prediction_summary", {}
                ),
            }
        except Exception as e:
            logger.error(f"å‡†å¤‡æŠ¥å‘Šæ•°æ®å¤±è´¥: {str(e)}")
            # è¿”å›åŸºæœ¬çš„å®‰å…¨æ•°æ®
            return {
                "prediction_type": context.prediction_type.value,
                "analysis_summary": "æ•°æ®å‡†å¤‡å¤±è´¥",
                "interpretation_summary": "è§£é‡Šæ•°æ®ä¸å¯ç”¨",
                "key_insights": context.insights or [],
                "quantitative_metrics": {},
                "scaling_count": 0,
                "anomaly_count": 0,
                "prediction_summary": {},
            }

    def _get_template_params(self, style: str) -> Dict[str, Any]:
        """è·å–æ¨¡æ¿å‚æ•°"""
        style_configs = {
            "professional": {"temperature": 0.2, "max_tokens": 1500, "tone": "formal"},
            "executive": {"temperature": 0.1, "max_tokens": 1200, "tone": "business"},
            "technical": {"temperature": 0.3, "max_tokens": 1800, "tone": "detailed"},
            "concise": {"temperature": 0.2, "max_tokens": 800, "tone": "brief"},
        }
        return style_configs.get(style, style_configs["professional"])

    async def _build_comprehensive_prompt(
        self,
        report_data: Dict[str, Any],
        template_params: Dict[str, Any],
        include_charts_desc: bool,
    ) -> str:
        """æ„å»ºç»¼åˆæŠ¥å‘Šæç¤º"""
        base_prompt = prompt_builder.build_comprehensive_report_prompt(
            prediction_type=PredictionType(report_data["prediction_type"]),
            analysis_context=report_data["analysis_summary"],
            prediction_results=report_data["prediction_summary"],
            scaling_recommendations=[f"å»ºè®®{report_data['scaling_count']}é¡¹æ‰©ç¼©å®¹æ“ä½œ"],
            cost_analysis="æˆæœ¬åˆ†ææ•°æ®",
            insights=report_data["key_insights"],
        )

        if include_charts_desc:
            charts_addition = """

## ğŸ“Š æ•°æ®å¯è§†åŒ–å»ºè®®
å»ºè®®ç”Ÿæˆçš„å›¾è¡¨å’Œå¯è§†åŒ–å†…å®¹ï¼š
- é¢„æµ‹è¶‹åŠ¿å›¾
- ç½®ä¿¡åŒºé—´å›¾  
- å¼‚å¸¸ç‚¹æ ‡æ³¨
- èµ„æºåˆ©ç”¨ç‡å¯¹æ¯”"""
            base_prompt += charts_addition

        return base_prompt

    async def _generate_executive_summary(
        self, context: ReportContext, full_report: str
    ) -> str:
        """ç”Ÿæˆæ‰§è¡Œæ‘˜è¦"""
        try:
            summary_prompt = f"""åŸºäºä»¥ä¸‹å®Œæ•´çš„{context.prediction_type.value}åˆ†ææŠ¥å‘Šï¼Œæå–ç”Ÿæˆ200å­—ä»¥å†…çš„æ‰§è¡Œæ‘˜è¦ï¼š

å®Œæ•´æŠ¥å‘Šï¼š
{full_report[:800]}...

è¦æ±‚ï¼š
1. çªå‡ºæœ€å…³é”®çš„å‘ç°
2. æ˜ç¡®å»ºè®®çš„è¡ŒåŠ¨
3. è¯´æ˜æ—¶é—´ç´§è¿«æ€§
4. è¯­è¨€ç®€æ´æœ‰åŠ›

è¯·ç”Ÿæˆæ‰§è¡Œæ‘˜è¦ï¼š"""

            summary = await self.llm_service.generate_response(
                messages=[{"role": "user", "content": summary_prompt}],
                temperature=0.1,
                max_tokens=300,
                use_task_model=False,  # å¤æ‚æ“ä½œï¼šç”Ÿæˆæ‰§è¡Œæ‘˜è¦ï¼Œä½¿ç”¨ä¸»æ¨¡å‹
            )

            return summary if summary else self._get_fallback_executive_summary(context)

        except Exception as e:
            logger.error(f"ç”Ÿæˆæ‰§è¡Œæ‘˜è¦å¤±è´¥: {str(e)}")
            return self._get_fallback_executive_summary(context)

    def _extract_key_metrics(self, context: ReportContext) -> Dict[str, Any]:
        """æå–å…³é”®æŒ‡æ ‡"""
        metrics = self._safe_get_dict(context.quantitative_metrics)
        prediction_results = self._safe_get_dict(context.prediction_results)
        prediction_summary = self._safe_get_dict(
            self._safe_get_value(prediction_results, "prediction_summary", {})
        )

        # å®‰å…¨è·å–ç½®ä¿¡åº¦ç»Ÿè®¡ä¿¡æ¯
        confidence_stats = self._safe_get_dict(
            self._safe_get_value(metrics, "confidence_statistics", {})
        )
        prediction_accuracy = self._safe_get_value(
            confidence_stats, "mean_confidence", 0
        )

        # å®‰å…¨è·å–é¢„æµ‹æ‘˜è¦ä¿¡æ¯
        trend_direction = self._safe_get_value(prediction_summary, "trend", "unknown")
        peak_value = self._safe_get_value(prediction_summary, "max_value", 0)

        return {
            "prediction_accuracy": prediction_accuracy,
            "trend_direction": trend_direction,
            "peak_value": peak_value,
            "risk_level": self._assess_risk_level(context),
            "optimization_potential": self._assess_optimization_potential(context),
            "time_to_action": self._assess_time_to_action(context),
        }

    def _get_trend_summary(self, context: ReportContext) -> str:
        """è·å–è¶‹åŠ¿æ‘˜è¦"""
        prediction_results = self._safe_get_dict(context.prediction_results)
        prediction_summary = self._safe_get_dict(
            self._safe_get_value(prediction_results, "prediction_summary", {})
        )
        trend = self._safe_get_value(prediction_summary, "trend", "unknown")
        trend_map = {"increasing": "ä¸Šå‡", "decreasing": "ä¸‹é™", "stable": "ç¨³å®š"}
        return trend_map.get(trend, "æœªçŸ¥")

    def _assess_risk_level(self, context: ReportContext) -> str:
        """è¯„ä¼°é£é™©ç­‰çº§"""
        prediction_results = self._safe_get_dict(context.prediction_results)
        anomalies = self._safe_get_value(prediction_results, "anomaly_predictions", [])
        high_risk_anomalies = [
            a
            for a in anomalies
            if isinstance(a, dict) and a.get("impact_level") in ["high", "critical"]
        ]

        if len(high_risk_anomalies) > 2:
            return "é«˜é£é™©"
        elif len(high_risk_anomalies) > 0:
            return "ä¸­é£é™©"
        else:
            return "ä½é£é™©"

    def _get_cost_impact_summary(self, context: ReportContext) -> str:
        """è·å–æˆæœ¬å½±å“æ‘˜è¦"""
        if not context.cost_analysis:
            return "æœªåˆ†æ"

        cost_analysis = self._safe_get_dict(context.cost_analysis)
        savings_potential = self._safe_get_value(
            cost_analysis, "cost_savings_potential", 0
        )

        if savings_potential > 20:
            return "é«˜èŠ‚çœæ½œåŠ›"
        elif savings_potential > 5:
            return "ä¸­ç­‰èŠ‚çœæ½œåŠ›"
        else:
            return "ä½èŠ‚çœæ½œåŠ›"

    def _assess_data_quality(self, context: ReportContext) -> float:
        """è¯„ä¼°æ•°æ®è´¨é‡åˆ†æ•°"""
        score = 0.8  # åŸºç¡€åˆ†æ•°

        metrics = self._safe_get_dict(context.quantitative_metrics)
        pred_count = self._safe_get_value(metrics, "prediction_count", 0)

        if pred_count >= 24:
            score += 0.1
        elif pred_count < 12:
            score -= 0.1

        confidence_stats = self._safe_get_dict(
            self._safe_get_value(metrics, "confidence_statistics", {})
        )
        avg_confidence = self._safe_get_value(confidence_stats, "mean_confidence", 0)

        if avg_confidence > 0.8:
            score += 0.1
        elif avg_confidence < 0.6:
            score -= 0.1

        return min(1.0, max(0.0, score))

    def _format_prediction_overview(self, context: ReportContext) -> str:
        """æ ¼å¼åŒ–é¢„æµ‹æ¦‚è§ˆ"""
        try:
            prediction_results = self._safe_get_dict(context.prediction_results)
            prediction_summary = self._safe_get_dict(
                self._safe_get_value(prediction_results, "prediction_summary", {})
            )
            predicted_data = self._safe_get_value(
                prediction_results, "predicted_data", []
            )

            if not predicted_data:
                return "æš‚æ— é¢„æµ‹æ•°æ®"

            overview = f"""é¢„æµ‹ç±»å‹: {context.prediction_type.value}
å½“å‰å€¼: {self._safe_get_value(prediction_results, "current_value", "N/A")}
é¢„æµ‹æ—¶é•¿: {self._safe_get_value(prediction_results, "prediction_hours", "N/A")}å°æ—¶
é¢„æµ‹ç‚¹æ•°: {len(predicted_data)}ä¸ª
æœ€å¤§å€¼: {self._safe_get_value(prediction_summary, "max_value", "N/A")}
æœ€å°å€¼: {self._safe_get_value(prediction_summary, "min_value", "N/A")}
å¹³å‡å€¼: {self._safe_get_value(prediction_summary, "avg_value", "N/A")}
è¶‹åŠ¿: {self._safe_get_value(prediction_summary, "trend", "unknown")}"""

            return overview

        except Exception as e:
            logger.error(f"æ ¼å¼åŒ–é¢„æµ‹æ¦‚è§ˆå¤±è´¥: {str(e)}")
            return f"{context.prediction_type.value}é¢„æµ‹åˆ†æ"

    def _format_scaling_recommendations(self, context: ReportContext) -> str:
        """æ ¼å¼åŒ–æ‰©ç¼©å®¹å»ºè®®"""
        try:
            recommendations = context.scaling_recommendations

            if not recommendations:
                return "æš‚æ— æ‰©ç¼©å®¹å»ºè®®"

            formatted_recs = []
            for i, rec in enumerate(recommendations[:5], 1):
                action = rec.get("action", "unknown")
                trigger_time = rec.get("trigger_time", "N/A")
                confidence = rec.get("confidence", 0)
                reason = rec.get("reason", "N/A")

                rec_text = f"{i}. åŠ¨ä½œ: {action}, æ—¶é—´: {trigger_time}, ç½®ä¿¡åº¦: {confidence:.2f}, åŸå› : {reason}"
                formatted_recs.append(rec_text)

            return "\n".join(formatted_recs)

        except Exception as e:
            logger.error(f"æ ¼å¼åŒ–æ‰©ç¼©å®¹å»ºè®®å¤±è´¥: {str(e)}")
            return "æ‰©ç¼©å®¹å»ºè®®æ ¼å¼åŒ–å¤±è´¥"

    def _parse_action_plan(self, plan_text: str) -> List[Dict[str, Any]]:
        """è§£æè¡ŒåŠ¨è®¡åˆ’æ–‡æœ¬ä¸ºç»“æ„åŒ–æ•°æ®"""
        try:
            actions = []
            lines = plan_text.split("\n")
            current_action = {}

            for line in lines:
                line = line.strip()
                if not line:
                    continue

                if line.startswith(("1.", "2.", "3.", "4.", "5.", "##", "**")):
                    if current_action:
                        actions.append(current_action)
                    current_action = {
                        "title": line,
                        "details": [],
                        "priority": "medium",
                        "estimated_time": "æœªæŒ‡å®š",
                    }
                elif current_action and line.startswith(("-", "â€¢", "*")):
                    current_action["details"].append(line[1:].strip())
                elif current_action:
                    current_action["details"].append(line)

            if current_action:
                actions.append(current_action)

            return actions[:5]

        except Exception as e:
            logger.error(f"è§£æè¡ŒåŠ¨è®¡åˆ’å¤±è´¥: {str(e)}")
            return [
                {
                    "title": "è¡ŒåŠ¨è®¡åˆ’",
                    "details": ["è¯·æŸ¥çœ‹å®Œæ•´çš„è¡ŒåŠ¨è®¡åˆ’å†…å®¹"],
                    "priority": "medium",
                    "estimated_time": "å¾…è¯„ä¼°",
                }
            ]

    def _identify_priority_actions(
        self, parsed_actions: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """è¯†åˆ«ä¼˜å…ˆçº§è¡ŒåŠ¨é¡¹"""
        try:
            priority_actions = []
            high_priority_keywords = [
                "ç´§æ€¥",
                "ç«‹å³",
                "critical",
                "urgent",
                "å³æ—¶",
                "é«˜é£é™©",
            ]

            for action in parsed_actions:
                title = action.get("title", "").lower()
                details = " ".join(action.get("details", [])).lower()

                if any(
                    keyword in title or keyword in details
                    for keyword in high_priority_keywords
                ):
                    action["priority"] = "high"
                    priority_actions.append(action)
                elif len(priority_actions) < 2:
                    action["priority"] = "medium"
                    priority_actions.append(action)

            return priority_actions[:3]

        except Exception as e:
            logger.error(f"è¯†åˆ«ä¼˜å…ˆçº§è¡ŒåŠ¨å¤±è´¥: {str(e)}")
            return parsed_actions[:2]

    def _analyze_risks(self, context: ReportContext) -> Dict[str, Any]:
        """åˆ†æé£é™©"""
        try:
            prediction_results = self._safe_get_dict(context.prediction_results)
            anomalies = self._safe_get_value(
                prediction_results, "anomaly_predictions", []
            )

            critical_risks = []
            for anomaly in anomalies:
                if isinstance(anomaly, dict) and anomaly.get("impact_level") in [
                    "high",
                    "critical",
                ]:
                    critical_risks.append(
                        {
                            "type": anomaly.get("anomaly_type", "unknown"),
                            "score": anomaly.get("anomaly_score", 0),
                            "timestamp": anomaly.get("timestamp", ""),
                        }
                    )

            return {
                "critical_risks": critical_risks,
                "total_anomalies": len(anomalies),
                "risk_trend": "increasing" if len(critical_risks) > 2 else "stable",
            }
        except Exception:
            return {"critical_risks": [], "total_anomalies": 0, "risk_trend": "unknown"}

    def _calculate_risk_score(self, context: ReportContext) -> float:
        """è®¡ç®—é£é™©åˆ†æ•°"""
        try:
            risk_data = self._analyze_risks(context)
            critical_count = len(risk_data.get("critical_risks", []))
            total_anomalies = risk_data.get("total_anomalies", 0)

            if total_anomalies == 0:
                return 0.0

            risk_ratio = critical_count / total_anomalies
            return min(1.0, risk_ratio * 2)
        except Exception:
            return 0.5

    def _generate_risk_timeline(self, context: ReportContext) -> List[Dict[str, Any]]:
        """ç”Ÿæˆé£é™©æ—¶é—´çº¿"""
        try:
            risk_data = self._analyze_risks(context)
            critical_risks = risk_data.get("critical_risks", [])

            timeline = []
            for risk in critical_risks:
                timeline.append(
                    {
                        "time": risk.get("timestamp", ""),
                        "risk_type": risk.get("type", "unknown"),
                        "severity": "high" if risk.get("score", 0) > 0.7 else "medium",
                    }
                )

            return sorted(timeline, key=lambda x: x.get("time", ""))
        except Exception:
            return []

    def _assess_optimization_potential(self, context: ReportContext) -> str:
        """è¯„ä¼°ä¼˜åŒ–æ½œåŠ›"""
        try:
            scaling_recommendations = context.scaling_recommendations or []

            if len(scaling_recommendations) > 3:
                return "é«˜ä¼˜åŒ–æ½œåŠ›"
            elif len(scaling_recommendations) > 1:
                return "ä¸­ç­‰ä¼˜åŒ–æ½œåŠ›"
            else:
                return "ä½ä¼˜åŒ–æ½œåŠ›"
        except Exception:
            return "æœªçŸ¥"

    def _assess_time_to_action(self, context: ReportContext) -> str:
        """è¯„ä¼°è¡ŒåŠ¨æ—¶é—´ç´§è¿«æ€§"""
        try:
            risk_level = self._assess_risk_level(context)
            if risk_level == "é«˜é£é™©":
                return "ç«‹å³è¡ŒåŠ¨"
            elif risk_level == "ä¸­é£é™©":
                return "24å°æ—¶å†…"
            else:
                return "ä¸€å‘¨å†…"
        except Exception:
            return "å¾…è¯„ä¼°"

    def _assess_cost_optimization_priority(self, cost_data: Dict[str, Any]) -> str:
        """è¯„ä¼°æˆæœ¬ä¼˜åŒ–ä¼˜å…ˆçº§"""
        try:
            savings_potential = self._safe_get_value(
                cost_data, "cost_savings_potential", 0
            )
            if savings_potential > 30:
                return "é«˜ä¼˜å…ˆçº§"
            elif savings_potential > 10:
                return "ä¸­ä¼˜å…ˆçº§"
            else:
                return "ä½ä¼˜å…ˆçº§"
        except Exception:
            return "å¾…è¯„ä¼°"

    # é™çº§å’Œå¤‡ç”¨æ–¹æ¡ˆ
    def _generate_fallback_report(self, context: ReportContext) -> Dict[str, Any]:
        """ç”Ÿæˆé™çº§æŠ¥å‘Š"""
        fallback_content = f"""# {context.prediction_type.value.upper()}é¢„æµ‹åˆ†ææŠ¥å‘Š

## é¢„æµ‹æ¦‚è§ˆ
- é¢„æµ‹ç±»å‹: {context.prediction_type.value}
- ç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M")}
- åˆ†æçŠ¶æ€: åŸºç¡€æ¨¡å¼

## å…³é”®å‘ç°
{chr(10).join([f"- {insight}" for insight in context.insights[:5]])}

## å»ºè®®è¡ŒåŠ¨
- ç›‘æ§é¢„æµ‹è¶‹åŠ¿å˜åŒ–
- å…³æ³¨å¼‚å¸¸æŒ‡æ ‡å˜åŒ–
- æ ¹æ®ä¸šåŠ¡éœ€æ±‚è°ƒæ•´èµ„æºé…ç½®

*æ³¨ï¼šæ­¤æŠ¥å‘Šä¸ºé™çº§æ¨¡å¼ç”Ÿæˆï¼Œå»ºè®®ç»“åˆä¸“ä¸šåˆ†æã€‚*"""

        return {
            "status": "fallback",
            "report": {
                "executive_summary": f"{context.prediction_type.value}é¢„æµ‹åˆ†æå®Œæˆï¼Œè¯·æŸ¥çœ‹è¯¦ç»†å†…å®¹ã€‚",
                "full_content": fallback_content,
                "key_metrics": self._extract_key_metrics(context),
                "report_metadata": {
                    "generated_at": datetime.now(),
                    "prediction_type": context.prediction_type.value,
                    "report_style": "fallback",
                    "data_quality_score": 0.5,
                },
            },
        }

    def _generate_fallback_summary(self, context: ReportContext) -> Dict[str, Any]:
        """ç”Ÿæˆé™çº§æ‰§è¡Œæ‘˜è¦"""
        return {
            "status": "fallback",
            "summary": f"{context.prediction_type.value}é¢„æµ‹åˆ†æå·²å®Œæˆã€‚å»ºè®®å…³æ³¨é¢„æµ‹è¶‹åŠ¿å’Œæ‰©ç¼©å®¹å»ºè®®ï¼ŒåŠæ—¶é‡‡å–å¿…è¦çš„èµ„æºè°ƒæ•´æªæ–½ã€‚",
            "word_count": 50,
            "generated_at": datetime.now(),
        }

    def _get_fallback_executive_summary(self, context: ReportContext) -> str:
        """è·å–é™çº§æ‰§è¡Œæ‘˜è¦"""
        return f"{context.prediction_type.value}é¢„æµ‹æ˜¾ç¤º{self._get_trend_summary(context)}è¶‹åŠ¿ï¼Œé£é™©ç­‰çº§{self._assess_risk_level(context)}ã€‚å»ºè®®å…³æ³¨{len(context.scaling_recommendations)}é¡¹æ‰©ç¼©å®¹å»ºè®®å¹¶åŠæ—¶æ‰§è¡Œã€‚"

    def _generate_fallback_action_plan(
        self, context: ReportContext, time_horizon: str
    ) -> Dict[str, Any]:
        """ç”Ÿæˆé™çº§è¡ŒåŠ¨è®¡åˆ’"""
        fallback_plan = f"""åŸºäº{context.prediction_type.value}é¢„æµ‹ç»“æœçš„{time_horizon}è¡ŒåŠ¨è®¡åˆ’ï¼š

1. ç›‘æ§å…³é”®æŒ‡æ ‡å˜åŒ–
   - æŒç»­è§‚å¯Ÿ{context.prediction_type.value}æŒ‡æ ‡è¶‹åŠ¿
   - è®¾ç½®å‘Šè­¦é˜ˆå€¼

2. å‡†å¤‡æ‰©ç¼©å®¹èµ„æº
   - è¯„ä¼°å½“å‰èµ„æºé…ç½®
   - å‡†å¤‡æ‰©å®¹æ–¹æ¡ˆ

3. é£é™©è¯„ä¼°å’Œé¢„æ¡ˆ
   - è¯†åˆ«æ½œåœ¨é£é™©ç‚¹
   - åˆ¶å®šåº”æ€¥é¢„æ¡ˆ

*æ³¨ï¼šæ­¤ä¸ºé™çº§æ¨¡å¼ç”Ÿæˆçš„åŸºç¡€è¡ŒåŠ¨è®¡åˆ’ã€‚*"""

        return {
            "status": "fallback",
            "action_plan": {
                "time_horizon": time_horizon,
                "plan_content": fallback_plan,
                "parsed_actions": [
                    {
                        "title": "åŸºç¡€ç›‘æ§å’Œå‡†å¤‡",
                        "details": ["ç›‘æ§æŒ‡æ ‡", "å‡†å¤‡èµ„æº", "è¯„ä¼°é£é™©"],
                        "priority": "medium",
                        "estimated_time": time_horizon,
                    }
                ],
                "priority_actions": [],
                "generated_at": datetime.now(),
            },
        }

    def _generate_fallback_risk_assessment(
        self, context: ReportContext
    ) -> Dict[str, Any]:
        """ç”Ÿæˆé™çº§é£é™©è¯„ä¼°"""
        return {
            "status": "fallback",
            "risk_assessment": {
                "assessment_content": f"{context.prediction_type.value}é£é™©è¯„ä¼°æš‚æ—¶ä¸å¯ç”¨ï¼Œå»ºè®®äººå·¥è¯„ä¼°ã€‚",
                "risk_score": 0.5,
                "critical_risks": [],
                "risk_timeline": [],
                "generated_at": datetime.now(),
            },
        }
